{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LSTM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/content/drive/MyDrive/Class/Energy Technology and Management/Topic 05 - Project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "source": [
    "# Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_avg = pd.read_csv('data_processed.csv', parse_dates=['datetime'], index_col='datetime')\n",
    "df_avg.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## \\[Mod\\] Change the frequency of datetime here.\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df_avg.index.freq = 'D'"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_avg.plot(figsize=(10, 3))\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Scaling data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_avg['y (scaled)'] = scaler.fit_transform(df_avg[['y']])\n",
    "display(df_avg.head())"
   ]
  },
  {
   "source": [
    "# Converting time series into supervised data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## \\[Mod\\] Change the window size here."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_avg.copy()\n",
    "dft['split'] = ''\n",
    "for i in range(1, window_size + 1):\n",
    "    col = f\"t-{i}\" \n",
    "    dft[col] = dft.iloc[:,1].shift(i)\n",
    "dft = dft.dropna()"
   ]
  },
  {
   "source": [
    "# Split data into training and testing set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "n_rows = dft.shape[0]\n",
    "train_size = int(n_rows * (1-test_size))\n",
    "test_size = n_rows - train_size\n",
    "dft.iloc[0:train_size, 2] = 'train'\n",
    "dft.iloc[train_size:, 2] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = dft['split'] == 'train'\n",
    "X_train = dft[filt].iloc[:,3:].values\n",
    "y_train = dft[filt].iloc[:,1].values\n",
    "#\n",
    "filt = dft['split'] == 'test'\n",
    "X_test = dft[filt].iloc[:,3:].values\n",
    "y_test = dft[filt].iloc[:,1].values\n",
    "#\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "source": [
    "# Reshape input data for LSTM traning\n",
    "- Dimension: \\[samples, time steps, features\\]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rs = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_rs = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "#\n",
    "print(X_train_rs.shape)\n",
    "print(X_test_rs.shape)"
   ]
  },
  {
   "source": [
    "# Training model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "source": [
    "## \\[Mod\\] Change the model architecture here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear session\n",
    "clear_session()\n",
    "\n",
    "# Change the network architecture here\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(X_train_rs.shape[1], X_train_rs.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_rs, y_train, epochs=100, batch_size=10, validation_data=(X_test_rs, y_test), \n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=20)], verbose=1, shuffle=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "# Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new DataFrame to store results\n",
    "dft_result = dft.iloc[:,0:3]\n",
    "\n",
    "# Model predictions\n",
    "y_pred_train = model.predict(X_train_rs)\n",
    "y_pred_test = model.predict(X_test_rs)\n",
    "y_pred = np.concatenate((y_pred_train, y_pred_test), axis=0)\n",
    "\n",
    "# Invert predictions\n",
    "y_pred_train_pl = scaler.inverse_transform(y_pred_train)\n",
    "y_pred_test_pl = scaler.inverse_transform(y_pred_test)\n",
    "y_pred_pl = scaler.inverse_transform(y_pred)\n",
    "\n",
    "# Storing results\n",
    "dft_result['y_pred (scaled)'] = y_pred \n",
    "dft_result['y_pred'] = y_pred_pl"
   ]
  },
  {
   "source": [
    "# Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(df_eval):\n",
    "    MAE = df_eval['error'].abs().mean()\n",
    "    RMSE = np.sqrt((df_eval['error']**2).mean())\n",
    "    MAPE = df_eval['percentage'].abs().mean()\n",
    "    print(f\"-------\")\n",
    "    print(f\"Mean absolute error: {MAE:6.3f}\")\n",
    "    print(f\"Root mean squared error: {RMSE:6.3f}\")\n",
    "    print(f\"Mean absolute percentage error: {MAPE:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_result['error'] = dft_result['y'] - dft_result['y_pred']\n",
    "dft_result['percentage'] = dft_result['error']/dft_result['y']*100\n",
    "\n",
    "dft_eval = dft_result[dft_result['split'] == 'train']\n",
    "print(f\"Training\")\n",
    "model_eval(dft_eval)\n",
    "\n",
    "print(f\"\\nTesting\")\n",
    "dft_eval = dft_result[dft_result['split'] == 'test']\n",
    "model_eval(dft_eval)\n",
    "\n",
    "print(f\"\\nAll\")\n",
    "model_eval(dft_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "dft_plot = dft_result[dft_result['split'] == 'train']\n",
    "dft_plot[['y', 'y_pred']].plot(ax=ax1)\n",
    "ax1.set_title('Training data')\n",
    "\n",
    "dft_plot = dft_result[dft_result['split'] == 'test']\n",
    "dft_plot[['y', 'y_pred']].plot(ax=ax2)\n",
    "ax2.set_title('Testing data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Forecasting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Retrain the model with entire data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "X_train = dft.iloc[:,3:].values\n",
    "y_train = dft.iloc[:,1].values\n",
    "\n",
    "# Reshape data\n",
    "X_train_rs = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "\n",
    "print(X_train_rs.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_rs, y_train, epochs=100, batch_size=10, validation_data=(X_test_rs, y_test), \n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=20)], verbose=1, shuffle=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Storing prediction result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train_rs)\n",
    "y_pred_pl = scaler.inverse_transform(y_pred)\n",
    "dft_result['y_pred_2 (scale)'] = y_pred\n",
    "dft_result['y_pred_2'] = y_pred_pl\n",
    "display(dft_result.head())"
   ]
  },
  {
   "source": [
    "## Forecasting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_forecast = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dft_result['y (scaled)'].values\n",
    "freq = dft_result.index.freq\n",
    "dt_last = dft_result.index[-1]\n",
    "dts = []\n",
    "for i in range(1,n_forecast+1):\n",
    "    x = y[-window_size-1:-1]\n",
    "    x = x.reshape(1,1,-1)\n",
    "    y = np.append(y,model.predict(x).flatten())\n",
    "    dts.append(dt_last + freq * i)\n",
    "\n",
    "y_fore = y[-n_forecast-1:-1]\n",
    "y_fore_pl = scaler.inverse_transform([y_fore]).ravel()\n",
    "\n",
    "dft_forecast = pd.DataFrame( {'datetime': dts, 'y_pred (scaled)': y_fore, 'y_pred': y_fore_pl} )\n",
    "dft_forecast = dft_forecast.set_index('datetime')\n",
    "dft_forecast.head()"
   ]
  },
  {
   "source": [
    "# Plotting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "dft_result['y'].plot(ax=ax)\n",
    "dft_result['y_pred_2'].plot(ax=ax)\n",
    "dft_forecast['y_pred'].plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "dft_result['y'].plot(ax=ax)\n",
    "dft_result['y_pred_2'].plot(ax=ax)\n",
    "dft_forecast['y_pred'].plot(ax=ax,linestyle='--',marker='s')\n",
    "\n",
    "dt_start = dft_result.index[-n_forecast*8]\n",
    "dt_end = dft_forecast.index[-1]\n",
    "ax.set_xlim(dt_start,dt_end)"
   ]
  },
  {
   "source": [
    "# Writing data to files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_result.to_csv('data_LSTM_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_forecast.to_csv('data_LSTM_forecast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}